import streamlit as st
import json
import string
import re
from rank_bm25 import BM25Okapi
import logging

# --- PAGE SETUP ---
st.set_page_config(page_title="Legal Assistant", page_icon="üá∫üá¶", layout="centered")

# --- CUSTOM CSS ---
st.markdown("""
    <style>
    .result-card {
        background-color: white;
        padding: 18px;
        border-radius: 8px;
        margin-bottom: 12px;
        border: 1px solid #e1e4e8;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .meta-row {
        font-size: 0.85em;
        color: #006621;
        margin-bottom: 8px;
        font-weight: 500;
    }
    .article-title {
        color: #1a73e8;
        font-size: 1.2em;
        font-weight: 600;
        text-decoration: none;
        display: block;
        margin-bottom: 8px;
    }
    .snippet {
        font-size: 0.95em;
        color: #3c4043;
        line-height: 1.5;
    }
    </style>
""", unsafe_allow_html=True)

# --- üß† THE "BRAIN" (Stemmer) ---
def simple_ukrainian_stem(text):
    """
    Crude but fast stemmer. Removes common endings so '–∞–º–ø—É—Ç–∞—Ü—ñ—è' matches '–∞–º–ø—É—Ç–∞—Ü—ñ—î—é'.
    """
    text = text.lower()
    # List of common endings sorted by length
    endings = [
        '–æ–º—É', '–æ–≥–æ', '–æ—é', '–µ—é', '—î—é', '–∏–º', '—ñ–º', '—ñ–≤', '—ó–≤', '—è–º', '—è–º–∏', '–∞–º–∏', '–∏–º–∏', 
        '–∞', '—è', '—É', '—é', '—ñ', '–∏', '–µ', '—î' 
    ]
    words = text.split()
    stemmed_words = []
    
    for word in words:
        if len(word) > 3: # Keep >3 to handle short words like '—Å—É–¥'
            for ending in endings:
                if word.endswith(ending):
                    word = word[:-len(ending)]
                    break
        stemmed_words.append(word)
        
    return stemmed_words

# --- LOAD DATA ---
@st.cache_resource
def load_engine():
    data_files = [
        "civil_code_parsed.json", 
        "civil_procedure_code_parsed.json", 
        "family_code_parsed.json",
        "mobilization_parsed.json",
        "medical_parsed.json"
    ]
    all_articles = []
    
    for filepath in data_files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # Assign Tags
                if "civil_code" in filepath: tag = "–¶–ö–£ ‚Ä¢ –¶–∏–≤—ñ–ª—å–Ω–∏–π –∫–æ–¥–µ–∫—Å"
                elif "procedure" in filepath: tag = "–¶–ü–ö ‚Ä¢ –¶–∏–≤—ñ–ª—å–Ω–∏–π –ø—Ä–æ—Ü–µ—Å"
                elif "family" in filepath: tag = "–°–ö–£ ‚Ä¢ –°—ñ–º–µ–π–Ω–∏–π –∫–æ–¥–µ–∫—Å"
                elif "mobilization" in filepath: tag = "–ó–£ ‚Ä¢ –ú–æ–±—ñ–ª—ñ–∑–∞—Ü—ñ—è"
                elif "medical" in filepath: tag = "üè• –ú–°–ï–ö ‚Ä¢ –Ü–Ω–≤–∞–ª—ñ–¥–Ω—ñ—Å—Ç—å"
                else: tag = "–ó–∞–∫–æ–Ω"
                
                for doc in data:
                    doc['source_tag'] = tag
                all_articles.extend(data)
        except FileNotFoundError:
            continue
            
    # Tokenize using the Stemmer
    corpus_tokens = []
    for doc in all_articles:
        # We process the text to remove punctuation and then stem it
        clean_text = doc['text'].translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))
        corpus_tokens.append(simple_ukrainian_stem(clean_text))
        
    bm25 = BM25Okapi(corpus_tokens)
    return bm25, all_articles

try:
    bm25, articles = load_engine()
except Exception as e:
    st.error(f"Error loading system: {e}")
    st.stop()

# --- SIDEBAR ---
with st.sidebar:
    st.header("üá∫üá¶ Legal Assistant")
    st.caption("Mode: Intelligent Search")
    num_results = st.slider("Results", 1, 10, 8)

# --- MAIN UI ---
st.title("–®–≤–∏–¥–∫–∏–π –ø–æ—à—É–∫")
selected_chip = st.pills("–ü—Ä–∏–∫–ª–∞–¥–∏:", ["–†–æ–∑—ñ—Ä–≤–∞–Ω–Ω—è —à–ª—é–±—É", "–°–ø–∞–¥—â–∏–Ω–∞", "–ü–æ–∑–æ–≤–Ω–∞ –¥–∞–≤–Ω—ñ—Å—Ç—å", "–ù–∏—Ä–∫–∏"], selection_mode="single")

if selected_chip:
    user_query = st.text_input("–ü–æ—à—É–∫:", value=selected_chip)
else:
    user_query = st.text_input("–ü–æ—à—É–∫:", "")

# --- üîç HIGHLIGHT LOGIC (Fixed for Roman Numerals & Gold Color) ---
def highlight_text(text, query):
    if not query: return text
    words = query.split()
    for w in words:
        # Check if it looks like a Roman numeral (I, II, III, IV, V, X)
        # We include Ukrainian '–Ü' (Cyrillic) and English 'I' (Latin)
        is_roman = all(c in "IiVvXxl–Ü—ñ" for c in w)
        
        # Skip short words unless they are Roman numerals
        if len(w) < 3 and not is_roman:
            continue
            
        # Simple stemming for the highlight pattern
        stem = w[:-1] if len(w) > 4 else w
        
        # Regex to catch variations + Gold Background + Bold
        pattern = re.compile(f"({re.escape(stem)}[–∞-—è—ñ—ó—îa-z]*)", re.IGNORECASE)
        text = pattern.sub(r'<span style="background-color: #ffedb1; font-weight: bold; padding: 2px; border-radius: 3px;">\1</span>', text)
        
    return text

# --- EXECUTE SEARCH ---
if user_query:
    # 1. Stem the query
    clean_query = user_query.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))
    query_tokens = simple_ukrainian_stem(clean_query)
    
    # 2. CALCULATE SCORES (This must happen BEFORE logging)
    scores = bm25.get_scores(query_tokens)
    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:num_results]
    
    # 3. LOGGING (Now it is safe)
    logging.info(json.dumps({
        "event": "search",
        "query": user_query,
        "results": len([i for i in top_indexes if scores[i] > 0])
    }, ensure_ascii=False))
    
    st.markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç–∏")
    
    found = False
    for i in top_indexes:
        score = scores[i]
        if score > 0:
            found = True
            art = articles[i]
            
            # Logic for Display Text
            safe_text = art['text'].replace("<", "&lt;").replace(">", "&gt;")
            
            # FIX: Show full text for Medical (MSEC) records
            if "–ú–°–ï–ö" in art.get('source_tag', ''):
                preview_text = safe_text 
            else:
                preview_text = safe_text[:350].strip() + "..." if len(safe_text) > 350 else safe_text
                
            highlighted_preview = highlight_text(preview_text, user_query)
            
            # Render Card
            st.markdown(f"""
            <div class="result-card">
                <div class="meta-row">{art.get('source_tag')}</div>
                <a href="{art.get('url')}" target="_blank" class="article-title">
                    {art.get('article')}. {art.get('title')}
                </a>
                <div class="snippet">
                    {highlighted_preview}
                </div>
                <div style="margin-top: 10px; border-top: 1px solid #eee; padding-top: 5px; text-align: right;">
                    <a href="{art.get('url')}" target="_blank" style="color: #006621; font-size: 0.8em; text-decoration: none;">
                        üîó –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ Zakon.Rada.gov.ua ‚Üó
                    </a>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
    if not found:
        st.info("–ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")

# --- FOOTER ---
st.divider()
st.caption("""
    ‚ö†Ô∏è **Disclaimer:** –¶–µ–π —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —î –¥–æ–≤—ñ–¥–∫–æ–≤–∏–º. 
    –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –±–µ—Ä–µ—Ç—å—Å—è –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏—Ö –¥–∂–µ—Ä–µ–ª (zakon.rada.gov.ua) –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ. 
    –†–æ–∑—Ä–æ–±–Ω–∏–∫ –Ω–µ –Ω–µ—Å–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–æ—Å—Ç—ñ –∑–∞ —é—Ä–∏–¥–∏—á–Ω—ñ –Ω–∞—Å–ª—ñ–¥–∫–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –æ—Ç—Ä–∏–º–∞–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó. 
    –ó–∞–≤–∂–¥–∏ –ø–µ—Ä–µ–≤—ñ—Ä—è–π—Ç–µ –ø–µ—Ä—à–æ–¥–∂–µ—Ä–µ–ª–æ –∑–∞ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º.
""")